<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 11 Multiple regression | Essentials of Mathematics and Statistics</title>
<meta name="author" content="Anas A Rana">
<meta name="description" content="Previously we have only considered simple linear regression with one response variable and one feature. In this practical we will go through examples with multiple features: \[y = \beta_0 +...">
<meta name="generator" content="bookdown 0.40 with bs4_book()">
<meta property="og:title" content="Chapter 11 Multiple regression | Essentials of Mathematics and Statistics">
<meta property="og:type" content="book">
<meta property="og:description" content="Previously we have only considered simple linear regression with one response variable and one feature. In this practical we will go through examples with multiple features: \[y = \beta_0 +...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 11 Multiple regression | Essentials of Mathematics and Statistics">
<meta name="twitter:description" content="Previously we have only considered simple linear regression with one response variable and one feature. In this practical we will go through examples with multiple features: \[y = \beta_0 +...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><link href="libs/Manrope-0.4.9/font.css" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Fira%20Code:wght@100&amp;display=swap" rel="stylesheet">
<link href="libs/Spectral-0.4.9/font.css" rel="stylesheet">
<script src="libs/bs3compat-0.8.0/transition.js"></script><script src="libs/bs3compat-0.8.0/tabs.js"></script><script src="libs/bs3compat-0.8.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Essentials of Mathematics and Statistics</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Introduction to the Practical</a></li>
<li class="book-part">Probability in R</li>
<li><a class="" href="simulating-random-numbers.html"><span class="header-section-number">1</span> Simulating random numbers</a></li>
<li><a class="" href="markov-chains.html"><span class="header-section-number">2</span> Markov Chains</a></li>
<li><a class="" href="a-monopoly-simulation.html"><span class="header-section-number">3</span> A Monopoly simulation</a></li>
<li><a class="" href="monte-carlo-methods.html"><span class="header-section-number">4</span> Monte Carlo Methods</a></li>
<li><a class="" href="maximum-likelihood.html"><span class="header-section-number">5</span> Maximum Likelihood</a></li>
<li><a class="" href="confidence-intervals.html"><span class="header-section-number">6</span> Confidence Intervals</a></li>
<li><a class="" href="computational-testing-techniques.html"><span class="header-section-number">7</span> Computational Testing Techniques</a></li>
<li class="book-part">Statistical Modelling</li>
<li><a class="" href="representing-data-in-r.html"><span class="header-section-number">8</span> Representing Data in R</a></li>
<li><a class="" href="principal-component-analysis.html"><span class="header-section-number">9</span> Principal component analysis</a></li>
<li><a class="" href="linear-regression.html"><span class="header-section-number">10</span> Linear regression</a></li>
<li><a class="active" href="multiple-regression.html"><span class="header-section-number">11</span> Multiple regression</a></li>
<li><a class="" href="qq-plot.html"><span class="header-section-number">12</span> QQ Plot - How To Use And Interpret</a></li>
<li><a class="" href="generalised-linear-models.html"><span class="header-section-number">13</span> Generalised Linear Models</a></li>
<li class="book-part">Solutions</li>
<li><a class="" href="simSol.html"><span class="header-section-number">A</span> Solution: Simulations</a></li>
<li><a class="" href="mc-solution.html"><span class="header-section-number">B</span> Solution: Three state Markov Chain</a></li>
<li><a class="" href="monopolySol.html"><span class="header-section-number">C</span> Solution: Monopoly</a></li>
<li><a class="" href="solution-monte-carlo.html"><span class="header-section-number">D</span> Solution: Monte Carlo</a></li>
<li><a class="" href="sol-mle.html"><span class="header-section-number">E</span> Solution: Model Answers: MLE</a></li>
<li><a class="" href="sol-ex-CI.html"><span class="header-section-number">F</span> Solution: Confidence Interval</a></li>
<li><a class="" href="solution-computational-testing.html"><span class="header-section-number">G</span> Solution: Computational Testing</a></li>
<li><a class="" href="representing_data-sol.html"><span class="header-section-number">H</span> Solution: Representing Data</a></li>
<li><a class="" href="solution-linear-regression-and-correlation.html"><span class="header-section-number">I</span> Solution: Linear regression and Correlation</a></li>
<li class="book-part">APPENDIX</li>
<li><a class="" href="start.html">Getting started in R and Rstudio</a></li>
<li><a class="" href="data-sets.html">Data sets</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/anasrana/ems-practicals">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="multiple-regression" class="section level1" number="11">
<h1>
<span class="header-section-number">11</span> Multiple regression<a class="anchor" aria-label="anchor" href="#multiple-regression"><i class="fas fa-link"></i></a>
</h1>
<p>Previously we have only considered simple linear regression with one response variable and one feature. In this practical we will go through examples with multiple features:</p>
<p><span class="math display">\[y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \epsilon \]</span></p>
<p>For this practical we will use data that is already inbuilt in R or is part of the <code>MASS</code> package. The only thing we need to do to make the data available is load the <code>MASS</code> package.</p>
<!-- ```{r init}
# We load the MAASS package for plotting
library(MASS)

# We load the ggplot2 package for plotting
library(ggplot2)

``` -->
<div id="multiple-regression-1" class="section level2" number="11.1">
<h2>
<span class="header-section-number">11.1</span> Multiple regression<a class="anchor" aria-label="anchor" href="#multiple-regression-1"><i class="fas fa-link"></i></a>
</h2>
<p>For this part we will use the inbuilt <code>trees</code> dataset containing <code>Volume</code>, <code>Girth</code> and <code>Height</code> data for 31 trees.</p>
<p>First we revisit linear regression on this example, recall the function to fit a linear model <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code>. Consider <code>Volume</code> to be the response variable and <code>Girth</code> to be the covariate.</p>
<div class="sourceCode" id="cb225"><pre class="sourceCode numberSource r numberLines"><code class="sourceCode r"><span id="cb225-1"><a href="multiple-regression.html#cb225-1"></a>lr_fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(Volume <span class="sc">~</span> Girth, <span class="at">data =</span> trees)</span>
<span id="cb225-2"><a href="multiple-regression.html#cb225-2"></a><span class="fu">summary</span>(lr_fit)</span></code></pre></div>
<pre class="bg-info"><code>#&gt; 
#&gt; Call:
#&gt; lm(formula = Volume ~ Girth, data = trees)
#&gt; 
#&gt; Residuals:
#&gt;    Min     1Q Median     3Q    Max 
#&gt; -8.065 -3.107  0.152  3.495  9.587 
#&gt; 
#&gt; Coefficients:
#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept) -36.9435     3.3651  -10.98 7.62e-12 ***
#&gt; Girth         5.0659     0.2474   20.48  &lt; 2e-16 ***
#&gt; ---
#&gt; Signif. codes:  
#&gt; 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
#&gt; 
#&gt; Residual standard error: 4.252 on 29 degrees of freedom
#&gt; Multiple R-squared:  0.9353, Adjusted R-squared:  0.9331 
#&gt; F-statistic: 419.4 on 1 and 29 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>We will now consider a linear regression example with multiple covariates, <code>Girth</code> as well as <code>Height</code>. In this case of course we know that they are related so we do expect both covariates to be significant.</p>
<div class="sourceCode" id="cb227"><pre class="sourceCode numberSource r numberLines"><code class="sourceCode r"><span id="cb227-1"><a href="multiple-regression.html#cb227-1"></a>mr_fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(Volume <span class="sc">~</span> Girth <span class="sc">+</span> Height, <span class="at">data =</span> trees)</span>
<span id="cb227-2"><a href="multiple-regression.html#cb227-2"></a></span>
<span id="cb227-3"><a href="multiple-regression.html#cb227-3"></a></span>
<span id="cb227-4"><a href="multiple-regression.html#cb227-4"></a><span class="fu">summary</span>(mr_fit)</span></code></pre></div>
<pre class="bg-info"><code>#&gt; 
#&gt; Call:
#&gt; lm(formula = Volume ~ Girth + Height, data = trees)
#&gt; 
#&gt; Residuals:
#&gt;     Min      1Q  Median      3Q     Max 
#&gt; -6.4065 -2.6493 -0.2876  2.2003  8.4847 
#&gt; 
#&gt; Coefficients:
#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept) -57.9877     8.6382  -6.713 2.75e-07 ***
#&gt; Girth         4.7082     0.2643  17.816  &lt; 2e-16 ***
#&gt; Height        0.3393     0.1302   2.607   0.0145 *  
#&gt; ---
#&gt; Signif. codes:  
#&gt; 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
#&gt; 
#&gt; Residual standard error: 3.882 on 28 degrees of freedom
#&gt; Multiple R-squared:  0.948,  Adjusted R-squared:  0.9442 
#&gt; F-statistic:   255 on 2 and 28 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><em>Note</em>, in the formula you only enter the covariates and not the regression coefficients or any information regarding the noise.</p>
<p>Let us now look at RSS values, we can calculate the RSS for the <code>lf_fit</code> object by using <code>sum(residuals(lr_fit)^2)</code>. We see that the RSS for LR = 524.3 and the RSS for MR = 421.92. Therefore the fit has improved but the regression coefficient for <code>Height</code> is very small and not significant.</p>
<p>One reason for this is that the in the relationship between <code>Volume</code>, <code>Girth</code>, and <code>Height</code> is not additive but rather <code>Girth</code> and <code>Height</code> are multiplied. Using the fact that <span class="math inline">\(\log(a*b) = \log(a) + \log(b)\)</span> we can consider the log-transformed data in a linear model.</p>
<div class="sourceCode" id="cb229"><pre class="sourceCode numberSource r numberLines"><code class="sourceCode r"><span id="cb229-1"><a href="multiple-regression.html#cb229-1"></a>mrl_fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">log</span>(Volume) <span class="sc">~</span> <span class="fu">log</span>(Girth) <span class="sc">+</span> <span class="fu">log</span>(Height), <span class="at">data =</span> trees)</span>
<span id="cb229-2"><a href="multiple-regression.html#cb229-2"></a></span>
<span id="cb229-3"><a href="multiple-regression.html#cb229-3"></a><span class="fu">summary</span>(mrl_fit)</span></code></pre></div>
<pre class="bg-info"><code>#&gt; 
#&gt; Call:
#&gt; lm(formula = log(Volume) ~ log(Girth) + log(Height), data = trees)
#&gt; 
#&gt; Residuals:
#&gt;       Min        1Q    Median        3Q       Max 
#&gt; -0.168561 -0.048488  0.002431  0.063637  0.129223 
#&gt; 
#&gt; Coefficients:
#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept) -6.63162    0.79979  -8.292 5.06e-09 ***
#&gt; log(Girth)   1.98265    0.07501  26.432  &lt; 2e-16 ***
#&gt; log(Height)  1.11712    0.20444   5.464 7.81e-06 ***
#&gt; ---
#&gt; Signif. codes:  
#&gt; 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
#&gt; 
#&gt; Residual standard error: 0.08139 on 28 degrees of freedom
#&gt; Multiple R-squared:  0.9777, Adjusted R-squared:  0.9761 
#&gt; F-statistic: 613.2 on 2 and 28 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Now we see that the regression coefficient is large and both covariates are significant. This shows that we need to ensure we understand the relationship between covariates before we construct our model.</p>
</div>
<div id="categorical-covariates" class="section level2" number="11.2">
<h2>
<span class="header-section-number">11.2</span> Categorical covariates<a class="anchor" aria-label="anchor" href="#categorical-covariates"><i class="fas fa-link"></i></a>
</h2>
</div>
<div id="note" class="section level2 unnumbered rmdnote">
<h2>NOTE<a class="anchor" aria-label="anchor" href="#note"><i class="fas fa-link"></i></a>
</h2>
<p>In this section we will consider a dataset with a categorical covariate. We will use linear regression to explore the relationship between the response variable and the categorical covariate. This is a simple example to illustrate the interpretation of the coefficients in the model. This is not a general approach to using linear regression with categorical variables.</p>
</div>
<p>Recall from the lecture that covariates don’t need to be numerical but can also be <em>categorical</em>. We will now explore regression with a categorical variable. Load a new dataset which is included in the <code>MASS</code> package, you won’t be able to load this dataset if package isn’t installed. Load the dataset explore what the data looks like.</p>
<div class="sourceCode" id="cb231"><pre class="sourceCode numberSource r numberLines"><code class="sourceCode r"><span id="cb231-1"><a href="multiple-regression.html#cb231-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb231-2"><a href="multiple-regression.html#cb231-2"></a><span class="fu">data</span>(<span class="st">"birthwt"</span>)</span>
<span id="cb231-3"><a href="multiple-regression.html#cb231-3"></a></span>
<span id="cb231-4"><a href="multiple-regression.html#cb231-4"></a><span class="fu">head</span>(birthwt)</span></code></pre></div>
<pre class="bg-info"><code>#&gt;    low age lwt race smoke ptl ht ui ftv  bwt
#&gt; 85   0  19 182    2     0   0  0  1   0 2523
#&gt; 86   0  33 155    3     0   0  0  0   3 2551
#&gt; 87   0  20 105    1     1   0  0  0   1 2557
#&gt; 88   0  21 108    1     1   0  0  1   2 2594
#&gt; 89   0  18 107    1     1   0  0  1   0 2600
#&gt; 91   0  21 124    3     0   0  0  0   0 2622</code></pre>
<div class="sourceCode" id="cb233"><pre class="sourceCode numberSource r numberLines"><code class="sourceCode r"><span id="cb233-1"><a href="multiple-regression.html#cb233-1"></a><span class="fu">summary</span>(birthwt)</span></code></pre></div>
<pre class="bg-info"><code>#&gt;       low              age             lwt       
#&gt;  Min.   :0.0000   Min.   :14.00   Min.   : 80.0  
#&gt;  1st Qu.:0.0000   1st Qu.:19.00   1st Qu.:110.0  
#&gt;  Median :0.0000   Median :23.00   Median :121.0  
#&gt;  Mean   :0.3122   Mean   :23.24   Mean   :129.8  
#&gt;  3rd Qu.:1.0000   3rd Qu.:26.00   3rd Qu.:140.0  
#&gt;  Max.   :1.0000   Max.   :45.00   Max.   :250.0  
#&gt;       race           smoke             ptl        
#&gt;  Min.   :1.000   Min.   :0.0000   Min.   :0.0000  
#&gt;  1st Qu.:1.000   1st Qu.:0.0000   1st Qu.:0.0000  
#&gt;  Median :1.000   Median :0.0000   Median :0.0000  
#&gt;  Mean   :1.847   Mean   :0.3915   Mean   :0.1958  
#&gt;  3rd Qu.:3.000   3rd Qu.:1.0000   3rd Qu.:0.0000  
#&gt;  Max.   :3.000   Max.   :1.0000   Max.   :3.0000  
#&gt;        ht                ui              ftv        
#&gt;  Min.   :0.00000   Min.   :0.0000   Min.   :0.0000  
#&gt;  1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.0000  
#&gt;  Median :0.00000   Median :0.0000   Median :0.0000  
#&gt;  Mean   :0.06349   Mean   :0.1481   Mean   :0.7937  
#&gt;  3rd Qu.:0.00000   3rd Qu.:0.0000   3rd Qu.:1.0000  
#&gt;  Max.   :1.00000   Max.   :1.0000   Max.   :6.0000  
#&gt;       bwt      
#&gt;  Min.   : 709  
#&gt;  1st Qu.:2414  
#&gt;  Median :2977  
#&gt;  Mean   :2945  
#&gt;  3rd Qu.:3487  
#&gt;  Max.   :4990</code></pre>
<p>We will give the data more interpretable names and generally cleanup the data a little bit.</p>
<div class="sourceCode" id="cb235"><pre class="sourceCode numberSource r numberLines"><code class="sourceCode r"><span id="cb235-1"><a href="multiple-regression.html#cb235-1"></a><span class="co"># rename columns</span></span>
<span id="cb235-2"><a href="multiple-regression.html#cb235-2"></a><span class="fu">colnames</span>(birthwt) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"bwt_below_2500"</span>, <span class="st">"mother_age"</span>, <span class="st">"mother_weight"</span>, <span class="st">"race"</span>,</span>
<span id="cb235-3"><a href="multiple-regression.html#cb235-3"></a>                       <span class="st">"mother_smokes"</span>, <span class="st">"previous_prem_labor"</span>, <span class="st">"hypertension"</span>,</span>
<span id="cb235-4"><a href="multiple-regression.html#cb235-4"></a>                       <span class="st">"uterine_irr"</span>, <span class="st">"physician_visits"</span>, <span class="st">"bwt_grams"</span>)</span>
<span id="cb235-5"><a href="multiple-regression.html#cb235-5"></a></span>
<span id="cb235-6"><a href="multiple-regression.html#cb235-6"></a>birthwt<span class="sc">$</span>race <span class="ot">&lt;-</span> <span class="fu">factor</span>(<span class="fu">c</span>(<span class="st">"white"</span>, <span class="st">"black"</span>, <span class="st">"other"</span>)[birthwt<span class="sc">$</span>race])</span>
<span id="cb235-7"><a href="multiple-regression.html#cb235-7"></a>birthwt<span class="sc">$</span>mother_smokes <span class="ot">&lt;-</span> <span class="fu">factor</span>(<span class="fu">c</span>(<span class="st">"No"</span>, <span class="st">"Yes"</span>)[birthwt<span class="sc">$</span>mother_smokes <span class="sc">+</span> <span class="dv">1</span>])</span>
<span id="cb235-8"><a href="multiple-regression.html#cb235-8"></a>birthwt<span class="sc">$</span>uterine_irr <span class="ot">&lt;-</span> <span class="fu">factor</span>(<span class="fu">c</span>(<span class="st">"No"</span>, <span class="st">"Yes"</span>)[birthwt<span class="sc">$</span>uterine_irr <span class="sc">+</span> <span class="dv">1</span>])</span>
<span id="cb235-9"><a href="multiple-regression.html#cb235-9"></a>birthwt<span class="sc">$</span>hypertension <span class="ot">&lt;-</span> <span class="fu">factor</span>(<span class="fu">c</span>(<span class="st">"No"</span>, <span class="st">"Yes"</span>)[birthwt<span class="sc">$</span>hypertension <span class="sc">+</span> <span class="dv">1</span>])</span>
<span id="cb235-10"><a href="multiple-regression.html#cb235-10"></a></span>
<span id="cb235-11"><a href="multiple-regression.html#cb235-11"></a><span class="fu">ggplot</span>(birthwt, <span class="fu">aes</span>(<span class="at">x =</span> mother_smokes, <span class="at">y =</span> bwt_grams)) <span class="sc">+</span></span>
<span id="cb235-12"><a href="multiple-regression.html#cb235-12"></a>    <span class="fu">geom_boxplot</span>() <span class="sc">+</span></span>
<span id="cb235-13"><a href="multiple-regression.html#cb235-13"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Data on baby births in Springfield (1986)"</span>,</span>
<span id="cb235-14"><a href="multiple-regression.html#cb235-14"></a>         <span class="at">x =</span> <span class="st">"Does the mother smoke?"</span>,</span>
<span id="cb235-15"><a href="multiple-regression.html#cb235-15"></a>         <span class="at">y =</span> <span class="st">"Birth-weight [grams]"</span>)</span></code></pre></div>
<div class="inline-figure"><img src="multiple-regression_files/figure-html/bplt-1.png" width="95%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb236"><pre class="sourceCode numberSource r numberLines"><code class="sourceCode r"><span id="cb236-1"><a href="multiple-regression.html#cb236-1"></a><span class="fu">ggplot</span>(birthwt, <span class="fu">aes</span>(<span class="at">x =</span> mother_age, <span class="at">y =</span> bwt_grams, <span class="at">col =</span> mother_smokes)) <span class="sc">+</span></span>
<span id="cb236-2"><a href="multiple-regression.html#cb236-2"></a>    <span class="fu">geom_point</span>()</span></code></pre></div>
<div class="inline-figure"><img src="multiple-regression_files/figure-html/bwt_sct-1.png" width="95%" style="display: block; margin: auto;"></div>
<p>Now we perform linear regression using the categorical variable, it is no different than performing linear regression on numeric data. The difference is in interpretation.</p>
<div class="sourceCode" id="cb237"><pre class="sourceCode numberSource r numberLines"><code class="sourceCode r"><span id="cb237-1"><a href="multiple-regression.html#cb237-1"></a>bwt_fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(bwt_grams <span class="sc">~</span> mother_smokes, <span class="at">data =</span> birthwt)</span>
<span id="cb237-2"><a href="multiple-regression.html#cb237-2"></a></span>
<span id="cb237-3"><a href="multiple-regression.html#cb237-3"></a><span class="fu">summary</span>(bwt_fit)</span></code></pre></div>
<pre class="bg-info"><code>#&gt; 
#&gt; Call:
#&gt; lm(formula = bwt_grams ~ mother_smokes, data = birthwt)
#&gt; 
#&gt; Residuals:
#&gt;     Min      1Q  Median      3Q     Max 
#&gt; -2062.9  -475.9    34.3   545.1  1934.3 
#&gt; 
#&gt; Coefficients:
#&gt;                  Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept)       3055.70      66.93  45.653  &lt; 2e-16 ***
#&gt; mother_smokesYes  -283.78     106.97  -2.653  0.00867 ** 
#&gt; ---
#&gt; Signif. codes:  
#&gt; 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
#&gt; 
#&gt; Residual standard error: 717.8 on 187 degrees of freedom
#&gt; Multiple R-squared:  0.03627,    Adjusted R-squared:  0.03112 
#&gt; F-statistic: 7.038 on 1 and 187 DF,  p-value: 0.008667</code></pre>
<p>When you put a categorical variable in the formula for <code>lm</code> as in this case <code>bwt_grams ~ mother_smokes</code> where we have two levels in the categorical variable. If we consider this model as <span class="math inline">\(y = \beta_0 + \beta_1 x + \epsilon\)</span>
The coefficients in the model can be interpreted as follows:</p>
<ul>
<li>
<span class="math inline">\(\beta_0\)</span> is average birth weight where the mother was a non smoker</li>
<li>
<span class="math inline">\(\beta_0 + \beta_1\)</span> is the average birth weight where the mother is a smoker</li>
<li>
<span class="math inline">\(\beta_1\)</span> is the average difference in birth weight for babies between mother that were smokers and mothers that were non smokers.</li>
</ul>
<p>Categorical variables can also have more than two levels and in those cases each additional level can be interpreted in the same way.</p>
<div class="note">
<p>We have used linear regression for this but in general we don’t want to use simple linear regression for categorical variables, you can convince yourself that this is the case by plotting the data. We use this simple example to highlight the different interpretation of the coefficients.</p>
</div>
<div id="residuals" class="section level2" number="11.3">
<h2>
<span class="header-section-number">11.3</span> Residuals<a class="anchor" aria-label="anchor" href="#residuals"><i class="fas fa-link"></i></a>
</h2>
<p>Recall from the lectures the residuals are the differences between the observed data <span class="math inline">\(y\)</span> and the fitted values <span class="math inline">\(\hat{y}\)</span>. One of the assumptions we make in the simple linear regression model is that the residuals should be normally distributed. To extract residuals from an <code>lm</code> object we will use the <code><a href="https://rdrr.io/r/stats/residuals.html">residuals()</a></code> function.</p>
<div class="sourceCode" id="cb239"><pre class="sourceCode numberSource r numberLines"><code class="sourceCode r"><span id="cb239-1"><a href="multiple-regression.html#cb239-1"></a>residuals_df <span class="ot">&lt;-</span></span>
<span id="cb239-2"><a href="multiple-regression.html#cb239-2"></a><span class="fu">data.frame</span>(<span class="at">resid =</span> <span class="fu">residuals</span>(bwt_fit))</span>
<span id="cb239-3"><a href="multiple-regression.html#cb239-3"></a></span>
<span id="cb239-4"><a href="multiple-regression.html#cb239-4"></a><span class="fu">ggplot</span>(residuals_df, <span class="fu">aes</span>(<span class="at">x =</span> resid)) <span class="sc">+</span></span>
<span id="cb239-5"><a href="multiple-regression.html#cb239-5"></a>    <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">10</span>)</span></code></pre></div>
<div class="inline-figure"><img src="multiple-regression_files/figure-html/bwt_resid-1.png" width="95%" style="display: block; margin: auto;"></div>
<p>Even if we consider that these residuals look like they are normally distributed we need to get better understanding of this we will use the Q-Q Plot. You can take a look at the wiki to get a better understanding (<a href="https://en.wikipedia.org/wiki/Q%E2%80%93Q_plot">Q–Q plot - Wikipedia</a>). In simple terms if the residuals are normally distributed we expect them to be on the diagonal straight line on a Q-Q plot. The simplest way to get such a plot is using the <code><a href="https://rdrr.io/r/graphics/plot.default.html">plot()</a></code> function and specifically for an <code>lm</code> object it has an option <code>which =</code> that takes a numeric value depending on which plot you want to plot.</p>
<div class="sourceCode" id="cb240"><pre class="sourceCode numberSource r numberLines"><code class="sourceCode r"><span id="cb240-1"><a href="multiple-regression.html#cb240-1"></a><span class="fu">plot</span>(bwt_fit, <span class="at">which =</span> <span class="dv">2</span>)</span></code></pre></div>
<div class="inline-figure"><img src="multiple-regression_files/figure-html/qq-1.png" width="95%" style="display: block; margin: auto;"></div>
<p>As we can see in this example the residuals are very close to normal with some outliers especially towards larger values of the residual. This would indicate that the model as it stands does not fulfil that assumption fully but comes close.</p>
<p><font color="dodgerblue"><strong>There is a more detailed example on QQ plots and how to interpret them in the next practical, <a href="qq-plot.html#qq-plot">here</a>.</strong></font></p>
</div>
<div id="gradient-descent-algorithm" class="section level2" number="11.4">
<h2>
<span class="header-section-number">11.4</span> Gradient descent algorithm (+)<a class="anchor" aria-label="anchor" href="#gradient-descent-algorithm"><i class="fas fa-link"></i></a>
</h2>
<p>Finally, in todays practical we will implement the <em>gradient descent algorithm</em> which we discussed in the lecture. This is a slightly tricker practical, try to implement the algorithm yourself before looking at the full details.</p>
<p>For simplicity we will only consider the case with one covariate. In this section we will use simulated data and compare the results with <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code>. The model we will simulate from is:</p>
<p><span class="math display">\[y = 2 + 3 x + \epsilon\]</span></p>
<div class="sourceCode" id="cb241"><pre class="sourceCode numberSource r numberLines"><code class="sourceCode r"><span id="cb241-1"><a href="multiple-regression.html#cb241-1"></a><span class="co"># setting seed to be able to reproduce the simulation</span></span>
<span id="cb241-2"><a href="multiple-regression.html#cb241-2"></a><span class="fu">set.seed</span>(<span class="dv">200</span>)</span>
<span id="cb241-3"><a href="multiple-regression.html#cb241-3"></a></span>
<span id="cb241-4"><a href="multiple-regression.html#cb241-4"></a><span class="co"># number of samples</span></span>
<span id="cb241-5"><a href="multiple-regression.html#cb241-5"></a>n_sample <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb241-6"><a href="multiple-regression.html#cb241-6"></a></span>
<span id="cb241-7"><a href="multiple-regression.html#cb241-7"></a><span class="co"># We sample x values from a uniform distribution in the range [-5, 5]</span></span>
<span id="cb241-8"><a href="multiple-regression.html#cb241-8"></a>x <span class="ot">&lt;-</span> <span class="fu">runif</span>(n_sample, <span class="sc">-</span><span class="dv">5</span>, <span class="dv">5</span>)</span>
<span id="cb241-9"><a href="multiple-regression.html#cb241-9"></a><span class="co"># Next we compute y</span></span>
<span id="cb241-10"><a href="multiple-regression.html#cb241-10"></a>y <span class="ot">&lt;-</span> <span class="dv">3</span> <span class="sc">*</span> x <span class="sc">+</span> <span class="dv">2</span> <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="at">n =</span> n_sample, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb241-11"><a href="multiple-regression.html#cb241-11"></a></span>
<span id="cb241-12"><a href="multiple-regression.html#cb241-12"></a>sim_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)</span>
<span id="cb241-13"><a href="multiple-regression.html#cb241-13"></a></span>
<span id="cb241-14"><a href="multiple-regression.html#cb241-14"></a><span class="fu">ggplot</span>(sim_df, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span></span>
<span id="cb241-15"><a href="multiple-regression.html#cb241-15"></a>    <span class="fu">geom_point</span>()</span></code></pre></div>
<div class="inline-figure"><img src="multiple-regression_files/figure-html/sim-mr-1.png" width="95%" style="display: block; margin: auto;"></div>
<p>Recall that in gradient descent we want to minimise the Mean Squared Error (<span class="math inline">\(J(\beta)\)</span>) which is the cost function. The first step is to write this cost function in R. For simplicity we will use matrix multiplication, which in R is implemented as <code>%*%</code>. (<em>Note</em>, to get help on these function with special characters you can’t simply run the command <code>?%*%</code> instead you have to put it in quotes <code><a href="https://rdrr.io/r/base/matmult.html">?"%*%"</a></code>.)</p>
<div class="sourceCode" id="cb242"><pre class="sourceCode numberSource r numberLines"><code class="sourceCode r"><span id="cb242-1"><a href="multiple-regression.html#cb242-1"></a>cost_fn <span class="ot">&lt;-</span> <span class="cf">function</span>(X, y, coef) {</span>
<span id="cb242-2"><a href="multiple-regression.html#cb242-2"></a>    <span class="fu">sum</span>( (X <span class="sc">%*%</span> coef <span class="sc">-</span> y)<span class="sc">^</span><span class="dv">2</span> ) <span class="sc">/</span> (<span class="dv">2</span><span class="sc">*</span><span class="fu">length</span>(y))</span>
<span id="cb242-3"><a href="multiple-regression.html#cb242-3"></a>}</span></code></pre></div>
<p>To perform an optimisation we will have to initialise parameters, in general optimisation algorithms won’t always produce the same results for all choices of initialisations.</p>
<div class="sourceCode" id="cb243"><pre class="sourceCode numberSource r numberLines"><code class="sourceCode r"><span id="cb243-1"><a href="multiple-regression.html#cb243-1"></a><span class="co"># First we set alpha and the number of iterations we will perform</span></span>
<span id="cb243-2"><a href="multiple-regression.html#cb243-2"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.2</span></span>
<span id="cb243-3"><a href="multiple-regression.html#cb243-3"></a>num_iters <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb243-4"><a href="multiple-regression.html#cb243-4"></a></span>
<span id="cb243-5"><a href="multiple-regression.html#cb243-5"></a><span class="co"># next we will initialise regression coefficients</span></span>
<span id="cb243-6"><a href="multiple-regression.html#cb243-6"></a>coef <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>), <span class="at">nrow=</span><span class="dv">2</span>)</span>
<span id="cb243-7"><a href="multiple-regression.html#cb243-7"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, <span class="fu">matrix</span>(x))</span>
<span id="cb243-8"><a href="multiple-regression.html#cb243-8"></a>res <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="st">"list"</span>, num_iters)</span></code></pre></div>
<p>We now write a for loop to compute the optimisation, where we store the full history of the opmtimisation.</p>
<div class="sourceCode" id="cb244"><pre class="sourceCode numberSource r numberLines"><code class="sourceCode r"><span id="cb244-1"><a href="multiple-regression.html#cb244-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>num_iters) {</span>
<span id="cb244-2"><a href="multiple-regression.html#cb244-2"></a>  error <span class="ot">&lt;-</span> (X <span class="sc">%*%</span> coef <span class="sc">-</span> y)</span>
<span id="cb244-3"><a href="multiple-regression.html#cb244-3"></a>  delta <span class="ot">&lt;-</span> <span class="fu">t</span>(X) <span class="sc">%*%</span> error <span class="sc">/</span> <span class="fu">length</span>(y)</span>
<span id="cb244-4"><a href="multiple-regression.html#cb244-4"></a>  coef <span class="ot">&lt;-</span> coef <span class="sc">-</span> alpha <span class="sc">*</span> delta</span>
<span id="cb244-5"><a href="multiple-regression.html#cb244-5"></a>  res_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">itr =</span> i , <span class="at">cost =</span> <span class="fu">cost_fn</span>(X, y, coef),</span>
<span id="cb244-6"><a href="multiple-regression.html#cb244-6"></a>                   <span class="at">b0 =</span> coef[<span class="dv">1</span>], <span class="at">b1 =</span> coef[<span class="dv">2</span>])</span>
<span id="cb244-7"><a href="multiple-regression.html#cb244-7"></a></span>
<span id="cb244-8"><a href="multiple-regression.html#cb244-8"></a>  res[[i]] <span class="ot">&lt;-</span> res_df</span>
<span id="cb244-9"><a href="multiple-regression.html#cb244-9"></a>}</span></code></pre></div>
<p>We created a list to store results <code>res</code> it is possible to combine all results into a simple <code>data.frame</code> using the <code>bind_rows()</code> function from the <code>dplyr</code> package. If we look at the final values in the resulting variable we will</p>
<div class="sourceCode" id="cb245"><pre class="sourceCode numberSource r numberLines"><code class="sourceCode r"><span id="cb245-1"><a href="multiple-regression.html#cb245-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb245-2"><a href="multiple-regression.html#cb245-2"></a>res_df <span class="ot">&lt;-</span> <span class="fu">bind_rows</span>(res)</span>
<span id="cb245-3"><a href="multiple-regression.html#cb245-3"></a><span class="fu">tail</span>(res_df)</span></code></pre></div>
<pre class="bg-info"><code>#&gt;     itr      cost       b0       b1
#&gt; 95   95 0.5275707 2.034285 3.014512
#&gt; 96   96 0.5275707 2.034285 3.014512
#&gt; 97   97 0.5275707 2.034285 3.014512
#&gt; 98   98 0.5275707 2.034285 3.014512
#&gt; 99   99 0.5275707 2.034285 3.014512
#&gt; 100 100 0.5275707 2.034285 3.014512</code></pre>
<p>We can see that <span class="math inline">\(\beta_0 = 2\)</span> and <span class="math inline">\(\beta_1 = 3\)</span> are reproduced faithfully. There are a few ways to visualise the optimisation. We can look at the convergence of the parameters, the cost function itself or even the estimated <span class="math inline">\(y\)</span> at each step of the optimisation.</p>
<div class="sourceCode" id="cb247"><pre class="sourceCode numberSource r numberLines"><code class="sourceCode r"><span id="cb247-1"><a href="multiple-regression.html#cb247-1"></a><span class="fu">ggplot</span>(res_df, <span class="fu">aes</span>(<span class="at">x =</span> itr, <span class="at">y =</span> b1)) <span class="sc">+</span></span>
<span id="cb247-2"><a href="multiple-regression.html#cb247-2"></a>    <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb247-3"><a href="multiple-regression.html#cb247-3"></a>    <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Iteration"</span>,</span>
<span id="cb247-4"><a href="multiple-regression.html#cb247-4"></a>         <span class="at">y =</span> <span class="st">"Estimated beta_1"</span>,</span>
<span id="cb247-5"><a href="multiple-regression.html#cb247-5"></a>         <span class="at">title =</span> <span class="st">"Visuaslisation of the cconvergence of the beta_1 parameter"</span>)</span></code></pre></div>
<div class="inline-figure"><img src="multiple-regression_files/figure-html/vis_gd-1.png" width="95%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb248"><pre class="sourceCode numberSource r numberLines"><code class="sourceCode r"><span id="cb248-1"><a href="multiple-regression.html#cb248-1"></a><span class="fu">ggplot</span>(res_df, <span class="fu">aes</span>(<span class="at">x =</span> itr, <span class="at">y =</span> cost)) <span class="sc">+</span></span>
<span id="cb248-2"><a href="multiple-regression.html#cb248-2"></a>    <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb248-3"><a href="multiple-regression.html#cb248-3"></a>    <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Iteration"</span>,</span>
<span id="cb248-4"><a href="multiple-regression.html#cb248-4"></a>         <span class="at">y =</span> <span class="st">"Cost function"</span>,</span>
<span id="cb248-5"><a href="multiple-regression.html#cb248-5"></a>         <span class="at">title =</span> <span class="st">"History of cost function at each iteration"</span>)</span></code></pre></div>
<div class="inline-figure"><img src="multiple-regression_files/figure-html/vis_gd-2.png" width="95%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb249"><pre class="sourceCode numberSource r numberLines"><code class="sourceCode r"><span id="cb249-1"><a href="multiple-regression.html#cb249-1"></a><span class="fu">ggplot</span>(sim_df, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span></span>
<span id="cb249-2"><a href="multiple-regression.html#cb249-2"></a>    <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"red"</span>, <span class="at">alpha =</span> <span class="fl">0.3</span>) <span class="sc">+</span></span>
<span id="cb249-3"><a href="multiple-regression.html#cb249-3"></a>    <span class="fu">geom_abline</span>(<span class="at">data =</span> res_df, <span class="fu">aes</span>(<span class="at">intercept =</span> b0, <span class="at">slope =</span> b1),</span>
<span id="cb249-4"><a href="multiple-regression.html#cb249-4"></a>                <span class="at">alpha =</span> <span class="fl">0.3</span>, <span class="at">col =</span> <span class="st">"darkgreen"</span>, <span class="at">size =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb249-5"><a href="multiple-regression.html#cb249-5"></a>    <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"x"</span>, <span class="at">y =</span> <span class="st">"y"</span>,</span>
<span id="cb249-6"><a href="multiple-regression.html#cb249-6"></a>         <span class="at">title =</span> <span class="st">"Estimated response at each step during optimisation"</span>)</span></code></pre></div>
<pre><code>#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.
#&gt; ℹ Please use `linewidth` instead.
#&gt; This warning is displayed once every 8 hours.
#&gt; Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.</code></pre>
<div class="inline-figure"><img src="multiple-regression_files/figure-html/vis_gd-3.png" width="95%" style="display: block; margin: auto;"></div>
<p>Now compare these results to the ones obtained by fitting a linear model in R using the function <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code>, how different are the results. Try to reproduce these plots with <span class="math inline">\(\alpha =\)</span> (0.02, 0.1, 0.5), and different number of iterations in the optimisation and compare the estimated <span class="math inline">\(\hat{\beta}_0\)</span>, and <span class="math inline">\(\hat{\beta}_1\)</span> to the values you use during the simulation step. This will give you an idea how important the right choice of these two parameters is.</p>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="linear-regression.html"><span class="header-section-number">10</span> Linear regression</a></div>
<div class="next"><a href="qq-plot.html"><span class="header-section-number">12</span> QQ Plot - How To Use And Interpret</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#multiple-regression"><span class="header-section-number">11</span> Multiple regression</a></li>
<li><a class="nav-link" href="#multiple-regression-1"><span class="header-section-number">11.1</span> Multiple regression</a></li>
<li><a class="nav-link" href="#categorical-covariates"><span class="header-section-number">11.2</span> Categorical covariates</a></li>
<li><a class="nav-link" href="#note">NOTE</a></li>
<li><a class="nav-link" href="#residuals"><span class="header-section-number">11.3</span> Residuals</a></li>
<li><a class="nav-link" href="#gradient-descent-algorithm"><span class="header-section-number">11.4</span> Gradient descent algorithm (+)</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/anasrana/ems-practicals/blob/master/multiple-regression.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/anasrana/ems-practicals/edit/master/multiple-regression.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Essentials of Mathematics and Statistics</strong>" was written by Anas A Rana. It was last built on 2024-10-07.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
